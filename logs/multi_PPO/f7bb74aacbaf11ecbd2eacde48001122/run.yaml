comment: ''
commit: 4408ccfd14f51b980254c1ace8ab216684447ef0
commit_message: Added new implementation of PPO algorithm...
is_dirty: true
load_run: breakout_PPO_389
name: multi_PPO
notes: ''
python_file: /Users/stanleyaraki/Desktop/PPO_389/Proximal-Policy-Optimization/multi_PPO.py
repo_remotes:
- https://github.com/StanleyAraki/Proximal-Policy-Optimization.git
start_step: 2
tags:
- PPO
- multi
trial_date: '2022-05-04'
trial_time: 09:41:57
uuid: f7bb74aacbaf11ecbd2eacde48001122
